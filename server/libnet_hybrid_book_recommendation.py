# -*- coding: utf-8 -*-
"""LibNet_Hybrid_Book_Recommendation_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Smnl3RY3aG8Fdc3XGXW7FybMXMuoN76j

# Book Recommender Model
This is a model which predict for every user the books he should read based on rating data, borrowed book history and similarity of books via tf-idf algorithm.
<br/>
The result of the model inserted to the mongodb database of LibNet.

## Imports
"""

#! pip install pymongo

#! pip install surprise

#! pip install python-dotenv


from pymongo import MongoClient
import json
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from surprise import Dataset, Reader, SVD, accuracy
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# for db configuration
from dotenv.main import load_dotenv
import os


"""## DB Info

Information to connect to the database
"""

load_dotenv()

# MongoDB Atlas connection details
mongo_username = os.environ['MONGO_USER']
mongo_password = os.environ['MONGO_PASS']
mongo_host = os.environ['MONGO_HOST']
mongo_db = os.environ['MONGO_DB']

# Connection URI for MongoDB Atlas
connection_uri = f"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_host}/{mongo_db}?retryWrites=true&w=majority"

"""## Load Data

Get the data from the database (mongodb)


"""

# Connect to MongoDB Atlas
client = MongoClient(connection_uri)
db = client[mongo_db]

# Retrieve data from MongoDB collections
borrow_collection = db['borrowbooks']
ratings_collection = db['ratings']
books_collection = db['books']
users_collection = db['users']

# Convert MongoDB data to pandas dataframes
borrow_df = pd.DataFrame(list(borrow_collection.find()))
ratings_df = pd.DataFrame(list(ratings_collection.find()))
books_df = pd.DataFrame(list(books_collection.find()))
users_df = pd.DataFrame(list(users_collection.find()))

# Close the MongoDB connection
client.close()

"""## Collaborative filtering - Predict Rate Model

Collaborative filtering using SVD algorithm to complete the missing intersections of rating between user and book
"""

# Preprocess data
combined_data = ratings_df[['idUser', 'idBook', 'rateNum']].copy()

# Split data into training and testing sets
train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42)

# Convert data to Surprise's Dataset format
reader = Reader(rating_scale=(1, 5))
train_set = Dataset.load_from_df(train_data, reader).build_full_trainset()

# Choose ML algorithm (SVD from Surprise library)
model = SVD(n_epochs=5)

# Train the model
model.fit(train_set)

# Evaluate the model
test_set = test_data[['idUser', 'idBook', 'rateNum']]
test_set = test_set.dropna()  # Drop any rows with missing values

predictions = model.test(test_set.values)

for i in predictions[:5]:
  print(i)

accuracy.rmse(predictions)

"""## Content based

Content-based filtering using book features - book name, author, category, publishing, summary and seriesName
"""

# Create TF-IDF matrix
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(books_df['bookName'].fillna('') + ' ' + books_df['author'].fillna('') + ' ' + books_df['category'].fillna('') + ' ' + books_df['publishing'].fillna('') +' ' + books_df['summary'].fillna('') + ' ' + books_df['seriesName'].fillna(''))

# Calculate cosine similarity matrix for content-based filtering
content_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""find top 50 similar books"""

def get_top_similar_books(user_id, num_books=50):
  # Get books borrowed by the user
  user_borrowed_books = borrow_df[borrow_df['idUser'] == user_id]['idBook'].values
  
  # Calculate similarity between borrowed books and all other books
  similarity_scores = content_similarity[user_borrowed_books].mean(axis=0)

  # Sort books by similarity and filter out borrowed books
  similar_books = pd.Series(similarity_scores, index=books_df.index)
  similar_books = similar_books.drop(user_borrowed_books, errors='ignore')
  similar_books = similar_books.nlargest(num_books)

  return similar_books

"""## Predict Hybrid
Predict for all of the users their recommended books
"""

def predict_books_by_user(user_id):

  top_similar_books = get_top_similar_books(user_id, num_books=50)
  
  top_similar_books_ratings = []
  for i , idBook in enumerate(top_similar_books.index):
    predicted_rate = model.predict(user_id, idBook).est
    similar_rate = top_similar_books.values[i]
    top_similar_books_ratings.append({"idBook": idBook, "rating": predicted_rate*0.3 + similar_rate*0.7 })
    
  # Sort the list of objects based on the 'rating' value in descending order
  sorted_books = sorted(top_similar_books_ratings, key=lambda x: x["rating"], reverse=True)

  # Get the top 5 idBook values with the highest ratings
  top_5_books = [book["idBook"] for book in sorted_books[:5]]
  
  return top_5_books

recommended_books = []
for idUser in users_df['idUser']:
  doc = {"idUser": idUser}
  predict_books = predict_books_by_user(idUser)
  doc["books"] = predict_books
  
  recommended_books.append(doc)


"""## Save To DB
 Save the result of the recommended books to the mongodb server
"""

# Connect to MongoDB Atlas
client = MongoClient(connection_uri)
db = client[mongo_db]

recommendations_collection = db["recommendations"]

# Delete all documents in the collection
recommendations_collection.delete_many({})

# Insert recommended_books into the recommendations collection
recommendations_collection.insert_many(recommended_books)

# Close the MongoDB connection
client.close()
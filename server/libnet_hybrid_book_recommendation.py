# -*- coding: utf-8 -*-
"""LibNet_Hybrid_Book_Recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xR-Q7t70hMcONRofCNKw-w-4_fGGOZ-i

# Book Recommender Model
This is a model which predict for every user the books he should read based on rating data, borrowed book history and similarity of books via tf-idf algorithm.
<br/>
The result of the model inserted to the mongodb database of LibNet.
## Imports
"""

from pymongo import MongoClient
import json
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from surprise import Dataset, Reader, SVD
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

"""## DB Info

Information to connect to the database
"""

# MongoDB Atlas connection details
mongo_username = 'rotemg'
mongo_password = 'LGTWKvafiyatoX3N'
mongo_host = 'clusterlibnet.6wi0mvp.mongodb.net'
mongo_port = 27017
mongo_db = 'libNet'

# Connection URI for MongoDB Atlas
connection_uri = f"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_host}/{mongo_db}?retryWrites=true&w=majority"

"""## Load Data

Get the data from the database (mongodb)


"""

# Connect to MongoDB Atlas
client = MongoClient(connection_uri)
db = client[mongo_db]

# Retrieve data from MongoDB collections
borrow_collection = db['borrowbooks']
ratings_collection = db['ratings']
books_collection = db['books']
users_collection = db['users']

# Get the ip address that run the colab notebook in order to add it to the whitelist of the database to allow connection
import requests

def get_ip():
    response = requests.get('https://api.ipify.org?format=json')
    ip_data = response.json()
    ip_address = ip_data['ip']
    return ip_address

# Call the function to get the IP address
ip = get_ip()
print(ip)

# Convert MongoDB data to pandas dataframes
borrow_df = pd.DataFrame(list(borrow_collection.find()))
ratings_df = pd.DataFrame(list(ratings_collection.find()))
books_df = pd.DataFrame(list(books_collection.find()))
users_df = pd.DataFrame(list(users_collection.find()))

# Close the MongoDB connection
client.close()

"""## Collaborative filtering - Predict Rate Model"""

# Preprocess data
combined_data = ratings_df[['idUser', 'idBook', 'rateNum']].copy()

# Split data into training and testing sets
train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42)

# Convert data to Surprise's Dataset format
reader = Reader(rating_scale=(1, 5))
train_set = Dataset.load_from_df(train_data, reader).build_full_trainset()

# Choose ML algorithm (SVD from Surprise library)
model = SVD()

# Train the model
model.fit(train_set)

# Evaluate the model
test_set = test_data[['idUser', 'idBook', 'rateNum']]
test_set = test_set.rename(columns={'idUser': 'uid', 'idBook': 'iid', 'rateNum': 'rating'})
test_set = test_set.dropna()  # Drop any rows with missing values

predictions = model.test(test_set.values)

mse = mean_squared_error(test_set['rating'], [pred.est for pred in predictions])
rmse = mse ** 0.5

print(f'Root Mean Squared Error (RMSE): {rmse}')

"""## Content based

Content-based filtering using book features - book name, author, and category
"""

# Create TF-IDF matrix
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(books_df['bookName'] + ' ' + books_df['author'] + ' ' + books_df['category'])


# Calculate cosine similarity matrix for content-based filtering
content_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""find top 50 similar books"""

def get_top_similar_books(user_id, num_books=50):
    # Get books borrowed by the user
    user_borrowed_books = borrow_df[borrow_df['idUser'] == user_id]['idBook'].values
    
    # Calculate average similarity with other books
    avg_similarity = content_similarity.mean(axis=1)

    # Sort books by similarity and filter out borrowed books
    similar_books = pd.Series(avg_similarity, index=books_df.index)
    similar_books = similar_books.drop(user_borrowed_books, errors='ignore')
    similar_books = similar_books.nlargest(num_books)

    return similar_books

"""## Predict Hybrid
Predict for all of the users their recommended books
"""

def predict_books_by_user(user_id):

  top_similar_books = get_top_similar_books(user_id, num_books=50)

  top_similar_books_ratings = []
  for idBook in top_similar_books.index:
    predicted_rate = model.predict(user_id, idBook).est
    top_similar_books_ratings.append({"idBook": idBook, "rating": predicted_rate })
    
  # Sort the list of objects based on the 'rating' value in descending order
  sorted_books = sorted(top_similar_books_ratings, key=lambda x: x["rating"], reverse=True)

  # Get the top 5 idBook values with the highest ratings
  top_5_books = [book["idBook"] for book in sorted_books[:5]]
  
  return top_5_books

recommended_books = []
for idUser in users_df['idUser']:
  doc = {"idUser": idUser}
  predict_books = predict_books_by_user(idUser)
  doc["books"] = predict_books
  
  recommended_books.append(doc)

len(users_df['idUser'])

len(recommended_books)

"""## Save To DB
 Save the result of the recommended books to the mongodb server
"""

# Connect to MongoDB Atlas
client = MongoClient(connection_uri)
db = client[mongo_db]

recommendations_collection = db["recommendations"]

# Delete all documents in the collection
recommendations_collection.delete_many({})

# Insert recommended_books into the recommendations collection
recommendations_collection.insert_many(recommended_books)

# Close the MongoDB connection
client.close()